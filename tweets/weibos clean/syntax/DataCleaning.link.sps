*this syntax is to clean the raw data of Sina Weibo from Sun.
**Generated by Lun, Sept.25, 2011. 

define !getdata_link (loops=!tokens(1))
!do !var=1 !to !loops

GET DATA
  /TYPE=TXT
  /FILE=!concat ("'E:\Sina Weibo\DATA_LINK\Rename\",!var,".txt'")
  /DELCASE=LINE
  /DELIMITERS="|"
  /ARRANGEMENT=DELIMITED
  /FIRSTCASE=1
  /IMPORTCASE=ALL
  /VARIABLES=
  V1 F10.0
  V2 F10.0.
CACHE.
EXECUTE.
DATASET NAME DataSet1 WINDOW=FRONT.
save out !concat(" 'E:\Sina Weibo\DATA_LINK\Rename\",!var,".sav' ") .
!doend. 
!enddefine. 
!getdata_link  loops=1359.
exe. 


***add a mark for further double-check. 

define !mark (loops=!tokens(1))
!do !var=1359 !to !loops
get file !concat(" 'E:\Sina Weibo\DATA_LINK\Rename\",!var,".sav' ") .
compute file=!var .
exe.
save out  !concat(" 'E:\Sina Weibo\DATA_LINK\Rename\",!var,".sav' ") .

!doend. 
!enddefine. 
!mark loops=1359.
exe. 



**aggergate for a node list. 
show miterate.
set miterate 2000.

define !aggregate (loops=!tokens(1))
!do !var=1 !to !loops

get file !concat(" 'E:\Sina Weibo\DATA_LINK\Rename\",!var,".sav' ") .
aggre out !concat(" 'D:\temp\sinaweibo\nodelist",!var,".sav' ")  /break=V1 file /n.v1=n(V1).
EXECUTE.
!doend.
!enddefine. 
!aggregate loops=1359.
exe.
save out 'D:\temp\sinaweibo\nodelist.link.all.filename.sav' .

***duplicate cases. 
sort cases by V1 file.
aggre out  /break=V1/n.dup=n(V1).
EXECUTE.
freq n.dup.
**There are some dupliccates, that is the same UID appeared in several files.
*** thus I have to further check whether the pair involving in the duplicates nodes is  replicates, or unique pairs. 
*** A case is node 1600788230 appeared in file 14,43,44,187. 
get file 'E:\Sina Weibo\DATA_LINK\Rename\14.sav'.
sel if V1=1600788230.
exe.
sort cases by V2. 
compute tag14=1.
save out 'D:\temp\sinaweibo\check1.sav'.

get file 'E:\Sina Weibo\DATA_LINK\Rename\43.sav'.
sel if V1=1600788230.
exe.
sort cases by V2. 
compute tag43=1.
save out 'D:\temp\sinaweibo\check2.sav'.

get file 'E:\Sina Weibo\DATA_LINK\Rename\44.sav'.
sel if V1=1600788230.
exe.
sort cases by V2. 
compute tag44=1.
save out 'D:\temp\sinaweibo\check4.sav'.


get file 'E:\Sina Weibo\DATA_LINK\Rename\187.sav'.
sel if V1=1600788230.
exe.
sort cases by V2. 
compute tag187=1.
save out 'D:\temp\sinaweibo\check3.sav'.

match files file  'D:\temp\sinaweibo\check3.sav'/file  'D:\temp\sinaweibo\check4.sav'
/file  'D:\temp\sinaweibo\check1.sav'/file 'D:\temp\sinaweibo\check2.sav'/by V2.
exe.
**According to the result file, there are some duplicate pairs. 

**create node list. 
get file 'D:\temp\sinaweibo\nodelist.link.all.filename.sav'.
aggre out */break=V1/n.V1=sum(n.v1).
exe. 
rename var V1=uid n.V1=n.following.
compute all.link=1.
exe. 
save out  'D:\temp\sinaweibo\nodelist.link.all.sav'.

***Nodelist in samplenetwork. 

GET DATA
  /TYPE=TXT
  /FILE="E:\Sina Weibo\sample network\SampleNetwork.txt"
  /DELCASE=LINE
  /DELIMITERS="|"
  /ARRANGEMENT=DELIMITED
  /FIRSTCASE=1
  /IMPORTCASE=ALL
  /VARIABLES=
  V1 F10.0
  V2 F10.0
  V3 F1.0.
CACHE.
EXECUTE.
DATASET NAME DataSet4 WINDOW=FRONT.
save out  'D:\temp\samplenet.sav'.
rename var V1=V2 V2=V1.
add files file * /file  'D:\temp\samplenet.sav'.
exe. 
sort cases by V1.
aggre out */break=V1/n=n(V1).
exe. 
rename var V1=uid n=n.sample.
compute samplenet=1.
exe.
save out  'D:\temp\samplenet.node.sav'.

*** Match nodelists (i.e., data_link, sample net and blogger list).
get file 'D:\Luheng\bloggerlist.sav'.
rename var blogid=uid.
sort cases by uid.
match files file */file  'D:\temp\samplenet.node.sav'/file   'D:\temp\sinaweibo\nodelist.link.all.sav'/by uid/map.
exe.



del var samplenet all.link.
rename var (n.sample=degree.tweet_retweets) (n.following=num.following) (articleid_nu=num.articles).
sort cases by  num.articles degree.tweet_retweets num.following (d).
freq num.articles degree.tweet_retweets num.following/format=notable.
GET FILE  'E:\Sina Weibo\CleanData\filename.retweet.sav'.
rename var newname=newname.re.
del var V1 V3.
match files file */file  'E:\Sina Weibo\CleanData\filename.tweet.sav'/by V2.
exe. 
rename var V2=uid.
sort cases by uid.
save out 'D:\temp\sinaweibo\nodelist.tweet.retweet.sav'.
get file  'E:\Sina Weibo\CleanData\nodelist.sav'.
sort cases by uid.
match files file */file 'D:\temp\sinaweibo\nodelist.tweet.retweet.sav'/by uid/map.
exe.
del var tag.
if num.articles>0 and newname>0 tag=1.
if newname>0 and num.following >0 tag=2.
if num.articles>0 and num.following >0 tag=3. 
if newname>0 and degree.tweet_retweets>0 tag=4.
if num.articles>0 and num.following >0  and newname>0  tag=5. 
exe.
freq tag.
***add files

get file  'D:\temp\sinaweibo\nodelist1.sav'.

define !addfile_nodelist_link (loops=!tokens(1))
!do !var=2 !to !loops
add files file * /file !concat(" 'D:\temp\sinaweibo\nodelist",!var,".sav' ").
exe. 
!doend. 
!enddefine. 
!addfile_nodelist_link loops=1359.
exe.



***to be deleted.


***add files.
***copy file 1.sav to first.sav.

get file ' E:\Sina Weibo\DATA_LINK\Rename\1.sav'.

define !addfile_link (loops=!tokens(1))
!do !var=1 !to !loops
add files file * /file !concat(" 'E:\Sina Weibo\DATA_LINK\Rename\",!var,".sav' ") .
exe. 
!doend. 
!enddefine. 
!addfile_link  loops=600.
exe.

save out 'E:\Sina Weibo\DATA_LINK\Rename\all1.sav'. 


get file ' E:\Sina Weibo\DATA_LINK\Rename\601.sav'.

define !addfile_link2 (loops=!tokens(1))
!do !var=602 !to !loops
add files file * /file !concat(" 'E:\Sina Weibo\DATA_LINK\Rename\",!var,".sav' ") .
exe. 
!doend. 
!enddefine. 
!addfile_link2  loops=1359.
exe.
save out 'E:\Sina Weibo\DATA_LINK\Rename\all2.sav'. 


